{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lung_tumor_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K1Wo3IuQ4DW"
      },
      "source": [
        "def categorize_label(lbl, ncls):\n",
        "  cat = to_categorical(lbl, num_classes = ncls)\n",
        "  return cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr4vOlMH363O"
      },
      "source": [
        "import cv2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def get_labeled_image(image, label, is_categorical=False):\n",
        "    if not is_categorical:\n",
        "        label = categorize_label(label, num_classes=4).astype(np.uint8)\n",
        "\n",
        "    image = cv2.normalize(image[:, :, :, 0], None, alpha=0, beta=255,\n",
        "                          norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(\n",
        "        np.uint8)\n",
        "\n",
        "    labeled_image = np.zeros_like(label[:, :, :, 1:])\n",
        "\n",
        "    # remove tumor part from image\n",
        "    labeled_image[:, :, :, 0] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 1] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 2] = image * (label[:, :, :, 0])\n",
        "\n",
        "\n",
        "    # color labels\n",
        "    labeled_image += label[:, :, :, 1:] * 255\n",
        "    return labeled_image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4U4Kmn555rG"
      },
      "source": [
        "import imageio\n",
        "from IPython.display import Image\n",
        "\n",
        "def visualize_data_gif(data_):\n",
        "    images = []\n",
        "    for i in range(data_.shape[0]):\n",
        "        x = data_[min(i, data_.shape[0] - 1), :, :]\n",
        "        y = data_[:, min(i, data_.shape[1] - 1), :]\n",
        "        z = data_[:, :, min(i, data_.shape[2] - 1)]\n",
        "        img = np.concatenate((x, y, z), axis=1)\n",
        "        images.append(img)\n",
        "    imageio.mimsave(\"/content/drive/MyDrive/training/gf.gif\", images, duration=0.03)\n",
        "    return Image(filename=\"/content/drive/MyDrive/training/gf.gif\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEAAgKAqL9ri"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "def plot_image_grid(image):\n",
        "    data_all = []\n",
        "\n",
        "    data_all.append(image)\n",
        "\n",
        "    fig, ax = plt.subplots(3, 6, figsize=[16, 9])\n",
        "\n",
        "    # coronal plane\n",
        "    coronal = np.transpose(data_all, [1, 3, 2, 4, 0])\n",
        "    coronal = np.rot90(coronal, 1)\n",
        "\n",
        "    # transversal plane\n",
        "    transversal = np.transpose(data_all, [2, 1, 3, 4, 0])\n",
        "    transversal = np.rot90(transversal, 2)\n",
        "\n",
        "    # sagittal plane\n",
        "    sagittal = np.transpose(data_all, [2, 3, 1, 4, 0])\n",
        "    sagittal = np.rot90(sagittal, 1)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(coronal.shape[2])\n",
        "        ax[0][i].imshow(np.squeeze(coronal[:, :, n, :]))\n",
        "        ax[0][i].set_xticks([])\n",
        "        ax[0][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[0][i].set_ylabel('Coronal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(transversal.shape[2])\n",
        "        ax[1][i].imshow(np.squeeze(transversal[:, :, n, :]))\n",
        "        ax[1][i].set_xticks([])\n",
        "        ax[1][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[1][i].set_ylabel('Transversal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(sagittal.shape[2])\n",
        "        ax[2][i].imshow(np.squeeze(sagittal[:, :, n, :]))\n",
        "        ax[2][i].set_xticks([])\n",
        "        ax[2][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[2][i].set_ylabel('Sagittal', fontsize=15)\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHglLUbJ9qpE"
      },
      "source": [
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_case(image_nifty_file, label_nifty_file):\n",
        "    # load the image and label file, get the image content and return a numpy array for each\n",
        "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
        "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
        "    \n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48jHjRi_7D6y"
      },
      "source": [
        "def show_slices(slices):\n",
        "   \n",
        "   fig, axes = plt.subplots(1, len(slices))\n",
        "   for i, slice in enumerate(slices):\n",
        "       axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijtfXMx-L6aV"
      },
      "source": [
        "def suit(image, window_center, window_width):\n",
        "  image_min = window_center - window_width//2\n",
        "  image_max = window_center + window_width//2\n",
        "  image[image<image_min] = image_min\n",
        "  image[image>image_max] = image_max\n",
        " \n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkPGTXxfBmDU"
      },
      "source": [
        "d = all_data[1].copy()\n",
        "ct = suit(d, -600, 1000)\n",
        "slice_0 = ct[190, :, :]\n",
        "slice_1 = ct[:, 157, :]\n",
        "slice_2 = ct[:, :, 150]\n",
        "show_slices([slice_0, slice_1, slice_2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ4Sbovthjt1"
      },
      "source": [
        "def intensity_bin(np_array, min, max):\n",
        "  clipped = np_array.clip(min, max)\n",
        "  clipped[clipped != max] = 1\n",
        "  clipped[clipped == max] = 0\n",
        "  return clipped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG-7fInFG0Vh"
      },
      "source": [
        "slice_0 = ct[0, :, :]\n",
        "slice_1 = ct[:, 0, :]\n",
        "slice_2 = ct[:, :, 100]\n",
        "show_slices([slice_0, slice_2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xB0LrjKm1zz"
      },
      "source": [
        "a = intensity_bin(all_data[8][:,:,150],0, 1000)\n",
        "plt.imshow(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J52WXHOseRn4"
      },
      "source": [
        "def show_contour(image, contours):\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.imshow(image.T, cmap = plt.cm.gray)\n",
        "  for contour in contours:\n",
        "    ax.plot(contour[:, 0], contour[:, 1], linewidth = 1)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JTU-QzmQGkq"
      },
      "source": [
        "import skimage.transform as skTrans\n",
        "\n",
        "def resize_nii(img):\n",
        "  rsd = skTrans.resize(img, (256,256,256,), order=1, preserve_range = True)\n",
        "  return rsd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nmh9eM1uc7wQ"
      },
      "source": [
        "rimg = resize_nii(trial)\n",
        "rmsk = resize_nii(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc0EJA16kuZR"
      },
      "source": [
        "def new_data(images, masks):\n",
        "  for image, mask in images, masks:\n",
        "    i = nib.save(image, )\n",
        "    m = nib.save(mask,  )\n",
        "    return i, m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QlXVX67LtBS",
        "outputId": "2cf1a717-6e0e-43e2-a52e-6a99e35c69c5"
      },
      "source": [
        "pip install patchify"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.19.5)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2zk7xbxYgWJ"
      },
      "source": [
        "from patchify import patchify\n",
        "\n",
        "pth_img = patchify(rimg, (64,64,64), step=64)\n",
        "pth_mask = patchify(rmsk, (64,64,64), step=64)\n",
        "\n",
        "input_img = np.reshape(pth_img, (-1, pth_img.shape[3], pth_img.shape[4], pth_img.shape[5]))\n",
        "input_mask = np.reshape(pth_mask, (-1, pth_mask.shape[3], pth_mask.shape[4], pth_mask.shape[5]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3M3XUzrF6Qz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e476c20e-101d-4c82-c50e-b664b22e31e9"
      },
      "source": [
        "train_img = np.stack((input_img,)*3, axis=-1)\n",
        "train_mask = np.expand_dims(input_mask, axis = 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 64, 64, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo9udP3gdsSt"
      },
      "source": [
        "train_img_mask = categorize_label(train_mask, ncls=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SABCGIxYVB1s",
        "outputId": "0bed1d20-f8da-47a8-aab3-0600f1c044ba"
      },
      "source": [
        "train_img_mask.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 64, 64, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJLQxpoOfCnU"
      },
      "source": [
        "**Model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Fw1t-oaCUX"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Activation, BatchNormalization, Conv3DTranspose\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Concatenate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQqfAUTj6vk3"
      },
      "source": [
        "def jaccard_coeff(y_true, y_pred):\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTvOOxr58Xx9"
      },
      "source": [
        "def jaccard_coeff_loss(y_true, y_pred):\n",
        "  return -jaccard_coeff(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FypO2miQ4Q3D"
      },
      "source": [
        "input_layer = Input(shape=(64, 64, 64, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoxAIWefuLJG"
      },
      "source": [
        "def bn_conv_block(input, num_filters):\n",
        "  x = Conv3D(num_filters, \n",
        "             kernel_size=(3,3,3),\n",
        "             padding='same',\n",
        "             strides=(1,1,1)\n",
        "              )(input_layer)  \n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x) \n",
        "\n",
        "  x =  Conv3D(num_filters, \n",
        "             kernel_size=(3,3,3),\n",
        "             padding='same',\n",
        "             strides=(1,1,1)\n",
        "              )(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzvr6A3ZwEP8"
      },
      "source": [
        "def dropout_conv_block(input, num_filters):\n",
        "  x = Conv3D(num_filters, \n",
        "             kernel_size=(3,3,3),\n",
        "             padding='same',\n",
        "             strides=(1,1,1)\n",
        "              )(input_layer)  \n",
        "  x = dropout(x)\n",
        "  x = Activation('relu')(x) \n",
        "\n",
        "  x =  Conv3D(num_filters, \n",
        "             kernel_size=(3,3,3),\n",
        "             padding='same',\n",
        "             strides=(1,1,1)\n",
        "              )(x)\n",
        "  x = dropout(x)\n",
        "  x = Activation('relu')(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcSp36CiwlQS"
      },
      "source": [
        "def encoder_block(input, num_filters):\n",
        "  x = bn_conv_block(input, num_filters)\n",
        "  p = MaxPooling3D(pool_size = (2,2,2))(x)\n",
        "  return x,p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ_vhx_dxRpa"
      },
      "source": [
        "def transpose_decoder_block(input,skip_features, num_filters):\n",
        "  x = Conv3DTranspose(num_filters, kernel_size=(2,2,2), strides=1, padding='same')(input)\n",
        "  x = Concatenate()([x, skip_features])\n",
        "  x = bn_conv_block(x, num_filters)\n",
        "  \n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR5LDHYozM8H"
      },
      "source": [
        "def Unet3D(input):\n",
        "\n",
        "  c1, p1 = encoder_block(input, 64)\n",
        "  c2, p2 = encoder_block(p1, 128)\n",
        "  c3, p3 = encoder_block(p2, 256)\n",
        "  c4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "  b1 = bn_conv_block(p4, 1024)\n",
        "  \n",
        "  d1 = transpose_decoder_block(b1, c4 , 512)\n",
        "  d2 = transpose_decoder_block(d1, c3, 256)\n",
        "  d3 = transpose_decoder_block(d2, c2, 128)\n",
        "  d4 = transpose_decoder_block(d3, c1, 64)\n",
        "\n",
        "  output = Conv3D(4, 1, padding='same', activation='sigmoid')(d4)\n",
        "\n",
        "  model = Model(input, output, name=\"U-Net\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuviRtL-fg0M"
      },
      "source": [
        "optimizer = Adam\n",
        "model = Unet3D(input_layer)\n",
        "model.compile(optimizer=optimizer(learning_rate=0.00001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['categorical_accuracy']\n",
        "             )\n",
        "#model.compile(optimizer=Adam(lr=0.00001),loss='jaccard_coeff_loss',metrics=['jaccard_coeff'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhCLa-14VN-t",
        "outputId": "38211269-a741-4274-eb61-a65857980bac"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"U-Net\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 64, 64, 64, 3)]   0         \n",
            "_________________________________________________________________\n",
            "conv3d_54 (Conv3D)           (None, 64, 64, 64, 64)    5248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_52 (Batc (None, 64, 64, 64, 64)    256       \n",
            "_________________________________________________________________\n",
            "activation_52 (Activation)   (None, 64, 64, 64, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_55 (Conv3D)           (None, 64, 64, 64, 64)    110656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_53 (Batc (None, 64, 64, 64, 64)    256       \n",
            "_________________________________________________________________\n",
            "activation_53 (Activation)   (None, 64, 64, 64, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv3d_56 (Conv3D)           (None, 64, 64, 64, 4)     260       \n",
            "=================================================================\n",
            "Total params: 116,676\n",
            "Trainable params: 116,420\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNmta1db9bv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183c16ff-c6c0-4d7e-caae-34fd102b7419"
      },
      "source": [
        "model.fit(train_img, train_img_mask, epochs = 5, steps_per_epoch = 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 355s 70s/step - loss: 0.9274 - categorical_accuracy: 0.0148\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 353s 71s/step - loss: 0.9018 - categorical_accuracy: 0.0145\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 350s 70s/step - loss: 0.8769 - categorical_accuracy: 0.0148\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 358s 72s/step - loss: 0.8554 - categorical_accuracy: 0.0195\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 349s 69s/step - loss: 0.8396 - categorical_accuracy: 0.0364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f22dd19f5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}